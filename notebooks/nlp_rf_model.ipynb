{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f353c401-2eaa-4ed6-af59-e1a885de871c",
   "metadata": {},
   "source": [
    "# Customer Sentiment Analysis Project  \n",
    "\n",
    "## Project Overview  \n",
    "This project aims to analyze customer sentiments based on product reviews collected from Flipkart.com. Using natural language processing (NLP) techniques and machine learning models, the project focuses on identifying customer sentiment as **positive**, **neutral**, or **negative**. The insights generated can help businesses understand customer feedback, improve their services, and make data-driven decisions for product development and marketing strategies.\n",
    "\n",
    "---\n",
    "\n",
    "## About the Dataset  \n",
    "\n",
    "### Dataset Description  \n",
    "The dataset comprises customer reviews of 104 product categories from Flipkart.com, including electronics, clothing, home decor, and automated systems. It contains **205,053 rows** and **6 columns**, providing detailed information about product reviews, ratings, and sentiments.\n",
    "\n",
    "## Data Dource\n",
    "\n",
    "This dataset is available on Kaggle in the following link:\n",
    "> https://www.kaggle.com/datasets/niraliivaghani/flipkart-product-customer-reviews-dataset\n",
    "\n",
    "### Features  \n",
    "\n",
    "| Column         | Description                                                                                     |\n",
    "|-----------------|-------------------------------------------------------------------------------------------------|\n",
    "| `Product_name` | Name of the product reviewed.                                                                   |\n",
    "| `Product_price`| Price of the product.                                                                           |\n",
    "| `Rate`         | Customer's rating of the product (on a scale of 1 to 5).                                        |\n",
    "| `Review`       | Text of the customer's review for each product.                                                 |\n",
    "| `Summary`      | Descriptive summary of the customer's thoughts about the product.                               |\n",
    "| `Sentiment`    | Multiclass label for sentiment: **Positive**, **Negative**, or **Neutral** (derived from Summary). |\n",
    "\n",
    "### Data Cleaning  \n",
    "- Missing values in the `Review` column are handled, and `NaN` values are included for products with no review but an available `Summary`.  \n",
    "- Data cleaning was performed using Python's `NumPy` and `Pandas` libraries.  \n",
    "- Sentiment labeling was conducted using the **VADER model** and manually validated for accuracy.  \n",
    "\n",
    "### Data Collection  \n",
    "The dataset was obtained via **web scraping** using the `BeautifulSoup` library from Flipkart.com in December 2022.\n",
    "\n",
    "---\n",
    "\n",
    "## Objectives  \n",
    "\n",
    "1. **Sentiment Analysis:**  \n",
    "   - Classify customer reviews as **Positive**, **Negative**, or **Neutral** using NLP models.  \n",
    "\n",
    "2. **Predictive Modeling:**  \n",
    "   - Use features like ratings, reviews, and summaries to predict customer behavior and product preferences.  \n",
    "\n",
    "3. **Text Classification:**  \n",
    "   - Develop text classification models for tasks such as spam detection, topic classification, and intent recognition.  \n",
    "\n",
    "4. **NLP Applications:**  \n",
    "   - Train and evaluate NLP algorithms for sentiment analysis and other domains.  \n",
    "\n",
    "5. **Customer Insights:**  \n",
    "   - Extract actionable insights from customer reviews to improve customer service and product offerings.  \n",
    "\n",
    "---\n",
    "\n",
    "## Usage  \n",
    "\n",
    "### Applications of the Dataset  \n",
    "1. **Sentiment Analysis:**  \n",
    "   Train models to classify customer sentiments for reviews and summaries.  \n",
    "\n",
    "2. **Predictive Modeling:**  \n",
    "   Predict customer behavior, purchase patterns, and product preferences based on reviews.  \n",
    "\n",
    "3. **Text Classification:**  \n",
    "   Develop models for spam detection, topic classification, and other text-based tasks.  \n",
    "\n",
    "4. **Customer Service Insights:**  \n",
    "   Identify customer complaints, issues, and suggestions to enhance service quality.  \n",
    "\n",
    "5. **Machine Learning Evaluation:**  \n",
    "   Evaluate and benchmark sentiment analysis models using this dataset.  \n",
    "\n",
    "---\n",
    "\n",
    "## Methodology  \n",
    "\n",
    "### 1. **Data Understanding**  \n",
    "   - Perform **Exploratory Data Analysis (EDA)** to uncover patterns and trends in the data.  \n",
    "   - Assess data quality and identify missing or inconsistent values.  \n",
    "\n",
    "### 2. **Data Preparation**  \n",
    "   - Handle missing values, duplicates, and outliers.  \n",
    "   - Normalize textual data and preprocess reviews for modeling (tokenization, stemming, and lemmatization).  \n",
    "   - Split data into **training**, **validation**, and **test** sets.  \n",
    "\n",
    "### 3. **Modeling**  \n",
    "   - **Baseline Models:** Use models like Naive Bayes for initial benchmarking.  \n",
    "   - **Advanced Models:** Train machine learning models such as Logistic Regression, SVM, and Random Forest.  \n",
    "   - **Deep Learning Models:** Implement LSTMs or Transformers (e.g., BERT) for advanced text analysis.  \n",
    "\n",
    "### 4. **Evaluation**  \n",
    "   - Evaluate model performance using metrics like accuracy, precision, recall, F1-score, and ROC-AUC.  \n",
    "   - Visualize confusion matrices and ROC curves for better understanding.  \n",
    "\n",
    "---\n",
    "\n",
    "## Tools and Technologies  \n",
    "\n",
    "- **Programming Language:** Python  \n",
    "- **Libraries:** pandas, numpy, matplotlib, seaborn, scikit-learn, nltk, spaCy, BeautifulSoup, TensorFlow/Keras  \n",
    "- **Models:** VADER, Logistic Regression, Naive Bayes, SVM, Random Forest, LSTM, BERT  \n",
    "- **Visualization Tools:** matplotlib, seaborn, plotly  \n",
    "\n",
    "---\n",
    "\n",
    "## Insights  \n",
    "\n",
    "1. **Sentiment Distribution:** Majority of reviews are positive, with a smaller proportion being neutral or negative.  \n",
    "2. **Product Insights:** Some categories (e.g., electronics) show higher customer satisfaction compared to others.  \n",
    "3. **Customer Behavior:** Pricing and ratings significantly influence sentiment.  \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Conclusion  \n",
    "\n",
    "The **Customer Sentiment Analysis Project** provides actionable insights into customer feedback, enabling businesses to refine their strategies, improve product offerings, and enhance customer experiences. By leveraging advanced NLP techniques and machine learning models, this project delivers significant value for customer-centric decision-making.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a55320-ec5c-4074-a377-7159abe3fdc2",
   "metadata": {},
   "source": [
    "### Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bb06940-342c-4741-85fd-221f13e6801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720e25b6-3084-4597-8c54-0f210a659f70",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "208bd6af-7dc7-41be-8ea3-e73814e41f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Path\n",
    "data_path = \"../data\"\n",
    "csv_path = os.path.join(data_path, \"Cleaned_SA.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a76473-0bb4-4b2b-ba9b-c266127315ec",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "312ecbe6-f5f6-4a8b-bca7-3452e2c56e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f23c7797-4135-4cae-b600-b861dacce62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Review</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>5</td>\n",
       "      <td>super!</td>\n",
       "      <td>great cooler excellent air flow and for this p...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>5</td>\n",
       "      <td>awesome</td>\n",
       "      <td>best budget 2 fit cooler nice cooling</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>3</td>\n",
       "      <td>fair</td>\n",
       "      <td>the quality is good but the power of air is de...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>1</td>\n",
       "      <td>useless product</td>\n",
       "      <td>very bad product its a only a fan</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>3</td>\n",
       "      <td>fair</td>\n",
       "      <td>ok ok product</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        product_name product_price Rate  \\\n",
       "0  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    5   \n",
       "1  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    5   \n",
       "2  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    3   \n",
       "3  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    1   \n",
       "4  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    3   \n",
       "\n",
       "            Review                                            Summary  \\\n",
       "0           super!  great cooler excellent air flow and for this p...   \n",
       "1          awesome              best budget 2 fit cooler nice cooling   \n",
       "2             fair  the quality is good but the power of air is de...   \n",
       "3  useless product                  very bad product its a only a fan   \n",
       "4             fair                                      ok ok product   \n",
       "\n",
       "  Sentiment  \n",
       "0  positive  \n",
       "1  positive  \n",
       "2  positive  \n",
       "3  negative  \n",
       "4   neutral  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0d4214-a218-4f93-81d3-e5d7f91eb92d",
   "metadata": {},
   "source": [
    "### Natural Language Processing(NLP)\n",
    "\n",
    "Preprocess the text with NLP to prepare the data for traing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2e52dd9-c0d3-4b8d-937a-2bb333823bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/arghadeysarkar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/arghadeysarkar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK(Natural Language Toolkit) resources\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d4d9f34-e6bf-46e5-96fd-c3b59ea4705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Preprocessing\n",
    "def preprocess_text(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    filtered_tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d7855cf-daef-49cb-9c3f-9860e11074ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training\n",
    "def prepare_to_train(data):\n",
    "\n",
    "    data['cleaned_review'] = data['Review'].apply(preprocess_text)\n",
    "    X = data['cleaned_review']\n",
    "    y = data['Sentiment']\n",
    "    \n",
    "    # Convert text to numerical data\n",
    "    vectorizer = CountVectorizer()\n",
    "    # vectorizer = TfidfVectorizer(max_features= 5000)\n",
    "    X_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "    return vectorizer, X_vectorized, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64e4f91f-f330-48bd-9af9-51390167fb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare text\n",
    "vectorizer, X, y = prepare_to_train(df)\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de02b4ee-236d-4794-a00b-4e5454f82abc",
   "metadata": {},
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "360a5441-314f-4548-bc2b-7debf8645a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(model):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate model\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe877b2c-4659-49a4-a218-32e134374779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.8970673917265488\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.75      0.79      4734\n",
      "     neutral       0.00      0.00      0.00      1679\n",
      "    positive       0.91      0.99      0.94     24481\n",
      "\n",
      "    accuracy                           0.90     30894\n",
      "   macro avg       0.58      0.58      0.58     30894\n",
      "weighted avg       0.85      0.90      0.87     30894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model = train_evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4364a824-44ee-49fb-a37b-4b81f97427a3",
   "metadata": {},
   "source": [
    "### Model Performance Analysis \n",
    "\n",
    "#### 1. Overall Model Performance\n",
    "\n",
    "- **Accuracy:**\n",
    "\n",
    "- The model achieves an accuracy of **88.88%**, which is relatively **high**.\n",
    "- However, accuracy alone is not a reliable metric in cases of imbalanced datasets, as it can be skewed by the dominant class.\n",
    "\n",
    "#### 2. Class-wise Performance Analysis\n",
    "\n",
    "- **Positive Sentiment:**\n",
    "\n",
    "    - **Precision: 0.90** The model is highly precise for positive sentiment, meaning most reviews predicted as positive are indeed positive.\n",
    "    - **Recall: 0.98** The recall is very high, indicating the model correctly identifies most positive reviews.\n",
    "    - **F1-Score: 0.94** The F1-score is excellent, reflecting a strong balance between precision and recall for this class.\n",
    "\n",
    "- **Observation:**\n",
    "\n",
    "    - The model performs extremely well for positive sentiments because they dominate the dataset, making the classifier biased toward this class.\n",
    "\n",
    "- **Negative Sentiment:**\n",
    "\n",
    "    - **Precision: 0.85** The model does well in predicting negative sentiments, meaning that when it predicts \"negative,\" it is correct **85%** of the time.\n",
    "    - **Recall: 0.71** The recall is lower, indicating the model misses some negative reviews.\n",
    "    - **F1-Score: 0.77** This score shows decent but not exceptional performance for negative sentiment.\n",
    "- **Observation:**\n",
    "\n",
    "    - The model struggles slightly with negative sentiments, possibly due to their smaller proportion in the dataset, leading to underrepresentation in training.\n",
    "\n",
    "- **Neutral Sentiment:**\n",
    "\n",
    "    - **Precision: 0.08** The precision is very low, meaning most reviews predicted as neutral are actually misclassified.\n",
    "    - **Recall: 0.00** The recall of 0 indicates that the model almost never predicts neutral reviews correctly.\n",
    "    - **F1-Score: 0.01** The F1-score is essentially negligible, highlighting that the model fails to capture neutral sentiments.\n",
    "- **Observation:**\n",
    "    - The model performs poorly on neutral sentiments, likely due to their very small representation in the dataset and their inherently ambiguous nature, which makes them harder to distinguish.\n",
    "\n",
    "#### 3. Macro vs. Weighted Averages\n",
    "\n",
    "- **Macro Average:**\n",
    "\n",
    "    - Precision, Recall, and F1-scores for macro averaging are around 0.57–0.61, reflecting poor performance across minority classes (negative and neutral).\n",
    "    - This suggests that the model does not generalize well to all classes.\n",
    "\n",
    "- **Weighted Average:**\n",
    "    - Precision, Recall, and F1-scores are around 0.85–0.89, which are much higher due to the heavy influence of the dominant positive class.\n",
    "\n",
    "- **Observation:**\n",
    "    - The weighted average is inflated by the high performance on positive sentiments, masking the poor results for negative and neutral classes.\n",
    "\n",
    "#### 4. Challenges with Class Imbalance\n",
    "    \n",
    "- The dataset is highly imbalanced, with the positive class making up the majority of the data (~80%).\n",
    "\n",
    "- This imbalance leads to:\n",
    "    - Excellent performance for the positive class.\n",
    "    - Decent performance for the negative class.\n",
    "    - Poor performance for the neutral class, as the model is biased toward the majority class.\n",
    "\n",
    "#### 5. Recommendations for Improvement\n",
    "\n",
    "- **Handle Class Imbalance:**\n",
    "\n",
    "    - Apply oversampling techniques like **SMOTE or ADASYN** for the minority classes (neutral and negative).\n",
    "    - Alternatively, use undersampling for the majority class (positive) to balance the dataset.\n",
    "\n",
    "- **Feature Engineering:**\n",
    "\n",
    "    - Explore additional text preprocessing steps, such as removing stop words, stemming/lemmatization, or using domain-specific dictionaries, to better capture nuances in neutral and negative sentiments.\n",
    "\n",
    "- Use a Different Algorithm:\n",
    "\n",
    "    - Consider more sophisticated models like **Logistic Regression with Class Weights, Random Forests, or Transformer-based models (e.g., BERT)**, which might handle imbalanced data better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9b5fdb-bd1b-4a32-a1e8-1fea49e6a523",
   "metadata": {},
   "source": [
    "### Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64621145-4932-46e8-a08a-e6f0a729e969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SMOTE(Synthetic Minority Oversampling Technique) for balacing the dataset\n",
    "smote = SMOTE(random_state= 42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e606310-13a4-4714-851e-c7a28ae1dec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.793001877387195\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.75      0.79      4734\n",
      "     neutral       0.13      0.45      0.21      1679\n",
      "    positive       0.96      0.82      0.89     24481\n",
      "\n",
      "    accuracy                           0.79     30894\n",
      "   macro avg       0.65      0.67      0.63     30894\n",
      "weighted avg       0.90      0.79      0.84     30894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retain the model\n",
    "model = train_evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71cc90cd-6054-4e34-a0ae-b98ef59bb63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SMOTE(Synthetic Minority Oversampling Technique) for balacing the dataset\n",
    "smote = SMOTE(random_state= 42)\n",
    "X_balanced, y_balanced = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc167935-133e-40ea-bbf8-4e35d6090710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning with GridSearchCV\n",
    "def tune_hyperparameter(model, param_grid, X, y):\n",
    "    # Define CV\n",
    "    gscv = GridSearchCV(model,\n",
    "                       param_grid= param_grid,\n",
    "                       cv= 5,\n",
    "                       verbose= 1)\n",
    "    # train the model\n",
    "    gscv.fit(X, y)\n",
    "\n",
    "    print(f\"Best Score: {gscv.best_score_: 0.2f}\")\n",
    "    best_params = gscv.best_params_\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def9f314-06b6-4296-82f6-f2742f85b247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    }
   ],
   "source": [
    "# Define heper parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'criterion': [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    'min_samples_split': [2, 3]\n",
    "}\n",
    "model_ht = RandomForestClassifier()\n",
    "best_params = tune_hyperparameter(model_ht, param_grid, X_balanced, y_balanced)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74dfcd90-2b7e-4c97-9407-bd585c399c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.7255130446041302\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.75      0.75      4734\n",
      "     neutral       0.11      0.50      0.18      1679\n",
      "    positive       0.96      0.74      0.83     24481\n",
      "\n",
      "    accuracy                           0.73     30894\n",
      "   macro avg       0.61      0.66      0.59     30894\n",
      "weighted avg       0.88      0.73      0.79     30894\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrain the model with best hyperparameter set\n",
    "model_opt = MultinomialNB(**best_params)\n",
    "model = train_evaluate(model_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b8fc8d-98a0-42ef-8153-ea3c0b964b19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
